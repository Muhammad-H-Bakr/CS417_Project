{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.11"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nmodel_training.py\n-----------------\nBuilds and trains the CNN model for fruit freshness classification.\nInputs: Data configuration from data_processing.py\nOutputs: Trained model (.keras file) and training history\n\"\"\"\n\nimport os\nimport pickle\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom pathlib import Path\nfrom sklearn.utils.class_weight import compute_class_weight\nimport math\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\nprint(\"=\" * 70)\nprint(\"ğŸ§  FRUIT FRESHNESS CLASSIFICATION - MODEL TRAINING\")\nprint(\"=\" * 70)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3hZLMskn89iX","outputId":"e2637997-e673-40b7-86fa-089a54fb3e77","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.599533Z","iopub.execute_input":"2025-12-13T15:40:57.600126Z","iopub.status.idle":"2025-12-13T15:40:57.605782Z","shell.execute_reply.started":"2025-12-13T15:40:57.600100Z","shell.execute_reply":"2025-12-13T15:40:57.604865Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nğŸ§  FRUIT FRESHNESS CLASSIFICATION - MODEL TRAINING\n======================================================================\n","output_type":"stream"}],"execution_count":79},{"cell_type":"code","source":"# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nBASE_PATH = Path.cwd()\nDATA_CONFIG_FILE = \"data_config.pkl\"\nMODEL_SAVE_PATH = \"best_fruit_freshness_model.keras\"\nHISTORY_SAVE_PATH = \"training_history.pkl\"\n\n# Training hyperparameters\nEPOCHS = 50\nLEARNING_RATE = 0.001\n\nprint(f\"ğŸ“ Working directory: {BASE_PATH}\")\nprint(f\"âš™ï¸  Epochs: {EPOCHS}\")\nprint(f\"âš™ï¸  Learning rate: {LEARNING_RATE}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YGZBv4G889ib","outputId":"4f420844-bd90-4b18-aefd-2badc4a4a01a","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.606796Z","iopub.execute_input":"2025-12-13T15:40:57.607013Z","iopub.status.idle":"2025-12-13T15:40:57.632436Z","shell.execute_reply.started":"2025-12-13T15:40:57.606998Z","shell.execute_reply":"2025-12-13T15:40:57.631742Z"}},"outputs":[{"name":"stdout","text":"ğŸ“ Working directory: /kaggle/working\nâš™ï¸  Epochs: 50\nâš™ï¸  Learning rate: 0.001\n","output_type":"stream"}],"execution_count":80},{"cell_type":"code","source":"# ============================================================================\n# LOAD DATA CONFIGURATION\n# ============================================================================\n\n\ndef load_data_config():\n    \"\"\"Load data configuration from data processing step.\"\"\"\n    if not os.path.exists(DATA_CONFIG_FILE):\n        raise FileNotFoundError(\n            f\"âŒ {DATA_CONFIG_FILE} not found! Please run 'data_processing.py' first.\"\n        )\n\n    with open(DATA_CONFIG_FILE, \"rb\") as f:\n        config = pickle.load(f)\n\n    print(\"\\nâœ… Data configuration loaded:\")\n    print(f\"  - Image size: {config['img_size']}\")\n    print(f\"  - Batch size: {config['batch_size']}\")\n    print(f\"  - Number of classes: {config['num_classes']}\")\n    print(f\"  - Training samples: {config['train_samples']}\")\n    print(f\"  - Validation samples: {config['val_samples']}\")\n\n    return config","metadata":{"id":"MRsPWj5Y89id","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.633505Z","iopub.execute_input":"2025-12-13T15:40:57.633674Z","iopub.status.idle":"2025-12-13T15:40:57.650403Z","shell.execute_reply.started":"2025-12-13T15:40:57.633662Z","shell.execute_reply":"2025-12-13T15:40:57.649636Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"# ============================================================================\n# RECREATE DATA GENERATORS\n# ============================================================================\n\n\ndef recreate_generators(config):\n    \"\"\"Recreate data generators from saved configuration.\"\"\"\n    print(\"\\nğŸ”„ Recreating data generators...\")\n\n    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rescale=1.0 / 255,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True,\n        zoom_range=0.2,\n        validation_split=config[\"validation_split\"],\n    )\n\n    test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255)\n\n    train_generator = train_datagen.flow_from_directory(\n        config[\"train_dir\"],\n        target_size=config[\"img_size\"],\n        batch_size=config[\"batch_size\"],\n        class_mode=\"categorical\",\n        subset=\"training\",\n        shuffle=True,\n    )\n\n    validation_generator = train_datagen.flow_from_directory(\n        config[\"train_dir\"],\n        target_size=config[\"img_size\"],\n        batch_size=config[\"batch_size\"],\n        class_mode=\"categorical\",\n        subset=\"validation\",\n        shuffle=True,\n    )\n\n    print(\"âœ… Generators recreated successfully\")\n    return train_generator, validation_generator","metadata":{"id":"PPgua6GB89if","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.651124Z","iopub.execute_input":"2025-12-13T15:40:57.651305Z","iopub.status.idle":"2025-12-13T15:40:57.666921Z","shell.execute_reply.started":"2025-12-13T15:40:57.651291Z","shell.execute_reply":"2025-12-13T15:40:57.666274Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# ============================================================================\n# MODEL ARCHITECTURE\n# ============================================================================\n\n\ndef create_cnn_model(input_shape=(100, 100, 3), num_classes=6):\n    \"\"\"Create a lightweight CNN for fruit freshness classification.\"\"\"\n    print(\"\\nğŸ§  Building CNN Model...\")\n\n    model = keras.Sequential(\n        [\n            # First Convolutional Block\n            layers.Conv2D(\n                32, (3, 3), activation=\"relu\", padding=\"same\", input_shape=input_shape\n            ),\n            layers.BatchNormalization(),\n            layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\"),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(2, 2),\n            layers.Dropout(0.25),\n            # Second Convolutional Block\n            layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n            layers.BatchNormalization(),\n            layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\"),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(2, 2),\n            layers.Dropout(0.25),\n            # Third Convolutional Block\n            layers.Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\"),\n            layers.BatchNormalization(),\n            layers.MaxPooling2D(2, 2),\n            layers.Dropout(0.25),\n            # Flatten and Dense Layers\n            layers.Flatten(),\n            layers.Dense(256, activation=\"relu\"),\n            layers.BatchNormalization(),\n            layers.Dropout(0.5),\n            layers.Dense(128, activation=\"relu\"),\n            layers.Dropout(0.5),\n            layers.Dense(num_classes, activation=\"softmax\"),\n        ]\n    )\n\n    return model","metadata":{"id":"T9oAxgoh89ih","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.668073Z","iopub.execute_input":"2025-12-13T15:40:57.668256Z","iopub.status.idle":"2025-12-13T15:40:57.687686Z","shell.execute_reply.started":"2025-12-13T15:40:57.668242Z","shell.execute_reply":"2025-12-13T15:40:57.686889Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"# ============================================================================\n# MODEL COMPILATION\n# ============================================================================\n\n\ndef compile_model(model, learning_rate=0.001):\n    \"\"\"Compile model with optimizer and metrics.\"\"\"\n    print(\"\\nâš™ï¸  Compiling model...\")\n\n    model.compile(\n        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n        loss=\"categorical_crossentropy\",\n        metrics=[\n            \"accuracy\",\n            keras.metrics.Precision(name=\"precision\"),\n            keras.metrics.Recall(name=\"recall\"),\n            keras.metrics.AUC(name=\"auc\"),\n        ],\n    )\n\n    print(\"âœ… Model compiled successfully\")\n    return model","metadata":{"id":"AzY-wC9f89in","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.701882Z","iopub.execute_input":"2025-12-13T15:40:57.702084Z","iopub.status.idle":"2025-12-13T15:40:57.706961Z","shell.execute_reply.started":"2025-12-13T15:40:57.702069Z","shell.execute_reply":"2025-12-13T15:40:57.706302Z"}},"outputs":[],"execution_count":84},{"cell_type":"code","source":"# ============================================================================\n# CALLBACKS SETUP\n# ============================================================================\n\n\ndef setup_callbacks():\n    \"\"\"Setup training callbacks.\"\"\"\n    callbacks = [\n        # Early stopping\n        keras.callbacks.EarlyStopping(\n            monitor=\"val_loss\",\n            patience=10,\n            restore_best_weights=True,\n            verbose=1,\n            mode=\"min\",\n        ),\n        # Learning rate reduction\n        keras.callbacks.ReduceLROnPlateau(\n            monitor=\"val_loss\",\n            factor=0.5,\n            patience=5,\n            min_lr=1e-7,\n            verbose=1,\n            mode=\"min\",\n        ),\n        # Model checkpoint\n        keras.callbacks.ModelCheckpoint(\n            MODEL_SAVE_PATH,\n            monitor=\"val_accuracy\",\n            save_best_only=True,\n            mode=\"max\",\n            verbose=1,\n        ),\n    ]\n\n    print(\"\\nğŸ“‹ Callbacks configured:\")\n    print(\"  1. Early Stopping (patience=10)\")\n    print(\"  2. ReduceLROnPlateau (factor=0.5, patience=5)\")\n    print(\"  3. Model Checkpoint (save best model)\")\n\n    return callbacks","metadata":{"id":"EGEmVaBV89iq","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.708240Z","iopub.execute_input":"2025-12-13T15:40:57.708578Z","iopub.status.idle":"2025-12-13T15:40:57.726252Z","shell.execute_reply.started":"2025-12-13T15:40:57.708561Z","shell.execute_reply":"2025-12-13T15:40:57.725641Z"}},"outputs":[],"execution_count":85},{"cell_type":"code","source":"# ============================================================================\n# CLASS WEIGHTS COMPUTATION\n# ============================================================================\n\n\ndef compute_class_weights(train_generator):\n    \"\"\"Compute class weights for imbalanced dataset.\"\"\"\n    print(\"\\nâš–ï¸  Computing class weights...\")\n\n    y_train = train_generator.classes\n    class_weights = compute_class_weight(\n        class_weight=\"balanced\", classes=np.unique(y_train), y=y_train\n    )\n    class_weights_dict = dict(enumerate(class_weights))\n\n    print(f\"Class weights: {class_weights_dict}\")\n    return class_weights_dict","metadata":{"id":"eGSJfUKn89iu","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.726962Z","iopub.execute_input":"2025-12-13T15:40:57.727325Z","iopub.status.idle":"2025-12-13T15:40:57.740747Z","shell.execute_reply.started":"2025-12-13T15:40:57.727309Z","shell.execute_reply":"2025-12-13T15:40:57.740075Z"}},"outputs":[],"execution_count":86},{"cell_type":"code","source":"# ============================================================================\n# TRAINING\n# ============================================================================\n\n\ndef train_model(model, train_gen, val_gen, callbacks, class_weights, epochs=30):\n    \"\"\"Train the model.\"\"\"\n    print(\"\\n\" + \"=\" * 70)\n    print(\"ğŸš€ STARTING TRAINING\")\n    print(\"=\" * 70)\n\n    train_steps = math.ceil(train_gen.samples / train_gen.batch_size)\n    val_steps = math.ceil(val_gen.samples / val_gen.batch_size)\n\n    history = model.fit(\n        train_gen,\n        steps_per_epoch=train_steps,\n        epochs=epochs,\n        validation_data=val_gen,\n        validation_steps=val_steps,\n        callbacks=callbacks,\n        class_weight=class_weights,\n        verbose=1,\n    )\n\n    print(\"\\nâœ… Training completed!\")\n    return history","metadata":{"id":"izeC9_As89iw","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.741411Z","iopub.execute_input":"2025-12-13T15:40:57.741670Z","iopub.status.idle":"2025-12-13T15:40:57.761362Z","shell.execute_reply.started":"2025-12-13T15:40:57.741647Z","shell.execute_reply":"2025-12-13T15:40:57.760688Z"}},"outputs":[],"execution_count":87},{"cell_type":"code","source":"# ============================================================================\n# SAVE TRAINING HISTORY\n# ============================================================================\n\n\ndef save_training_history(history):\n    \"\"\"Save training history for later analysis.\"\"\"\n    with open(HISTORY_SAVE_PATH, \"wb\") as f:\n        pickle.dump(history.history, f)\n\n    print(f\"\\nğŸ’¾ Training history saved to: {HISTORY_SAVE_PATH}\")","metadata":{"id":"4Dop8Eqr89ix","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.762647Z","iopub.execute_input":"2025-12-13T15:40:57.762883Z","iopub.status.idle":"2025-12-13T15:40:57.775731Z","shell.execute_reply.started":"2025-12-13T15:40:57.762868Z","shell.execute_reply":"2025-12-13T15:40:57.775126Z"}},"outputs":[],"execution_count":88},{"cell_type":"code","source":"# ============================================================================\n# MAIN EXECUTION\n# ============================================================================\n\nif __name__ == \"__main__\":\n    try:\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 1: LOAD DATA CONFIGURATION\")\n        print(\"=\" * 70)\n        config = load_data_config()\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 2: RECREATE DATA GENERATORS\")\n        print(\"=\" * 70)\n        train_gen, val_gen = recreate_generators(config)\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 3: BUILD MODEL\")\n        print(\"=\" * 70)\n        input_shape = (*config[\"img_size\"], 3)\n        model = create_cnn_model(\n            input_shape=input_shape, num_classes=config[\"num_classes\"]\n        )\n        model.summary()\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 4: COMPILE MODEL\")\n        print(\"=\" * 70)\n        model = compile_model(model, learning_rate=LEARNING_RATE)\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 5: SETUP CALLBACKS\")\n        print(\"=\" * 70)\n        callbacks = setup_callbacks()\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 6: COMPUTE CLASS WEIGHTS\")\n        print(\"=\" * 70)\n        class_weights = compute_class_weights(train_gen)\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 7: TRAIN MODEL\")\n        print(\"=\" * 70)\n        history = train_model(\n            model, train_gen, val_gen, callbacks, class_weights, epochs=EPOCHS\n        )\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"STEP 8: SAVE\")\n        print(\"=\" * 70)\n        save_training_history(history)\n\n        print(\"\\n\" + \"=\" * 70)\n        print(\"âœ… MODEL TRAINING COMPLETE!\")\n        print(\"=\" * 70)\n        print(f\"ğŸ“Š Model saved to: {MODEL_SAVE_PATH}\")\n        print(f\"ğŸ“Š History saved to: {HISTORY_SAVE_PATH}\")\n        print(f\"\\nâ¡ï¸  Next step: Run 'evaluation_testing.py'\")\n\n    except Exception as e:\n        print(f\"\\nâŒ Error during training: {e}\")\n        raise","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"JMGl3Vxq89i0","outputId":"8586f9b8-0a17-4124-8d84-8a9ac2c0aef4","trusted":true,"execution":{"iopub.status.busy":"2025-12-13T15:40:57.776455Z","iopub.execute_input":"2025-12-13T15:40:57.776765Z","iopub.status.idle":"2025-12-13T15:56:33.897499Z","shell.execute_reply.started":"2025-12-13T15:40:57.776742Z","shell.execute_reply":"2025-12-13T15:56:33.896853Z"}},"outputs":[{"name":"stdout","text":"\n======================================================================\nSTEP 1: LOAD DATA CONFIGURATION\n======================================================================\n\nâœ… Data configuration loaded:\n  - Image size: (100, 100)\n  - Batch size: 32\n  - Number of classes: 10\n  - Training samples: 11701\n  - Validation samples: 2919\n\n======================================================================\nSTEP 2: RECREATE DATA GENERATORS\n======================================================================\n\nğŸ”„ Recreating data generators...\nFound 11701 images belonging to 10 classes.\nFound 2919 images belonging to 10 classes.\nâœ… Generators recreated successfully\n\n======================================================================\nSTEP 3: BUILD MODEL\n======================================================================\n\nğŸ§  Building CNN Model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m896\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_42          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m128\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_36 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚         \u001b[38;5;34m9,248\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_43          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   â”‚           \u001b[38;5;34m128\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_21 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_35 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m32\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_37 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m18,496\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_44          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚           \u001b[38;5;34m256\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_38 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚        \u001b[38;5;34m36,928\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_45          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚           \u001b[38;5;34m256\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_36 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_39 (\u001b[38;5;33mConv2D\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m73,856\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_46          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚           \u001b[38;5;34m512\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_37 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18432\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚     \u001b[38;5;34m4,718,848\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_47          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\nâ”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_38 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_22 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_39 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_23 (\u001b[38;5;33mDense\u001b[0m)                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,290\u001b[0m â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_42          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_43          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_44          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_45          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ conv2d_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_46          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18432</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,718,848</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ batch_normalization_47          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\nâ”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dropout_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,894,762\u001b[0m (18.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,894,762</span> (18.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,893,610\u001b[0m (18.67 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,893,610</span> (18.67 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"\n======================================================================\nSTEP 4: COMPILE MODEL\n======================================================================\n\nâš™ï¸  Compiling model...\nâœ… Model compiled successfully\n\n======================================================================\nSTEP 5: SETUP CALLBACKS\n======================================================================\n\nğŸ“‹ Callbacks configured:\n  1. Early Stopping (patience=10)\n  2. ReduceLROnPlateau (factor=0.5, patience=5)\n  3. Model Checkpoint (save best model)\n\n======================================================================\nSTEP 6: COMPUTE CLASS WEIGHTS\n======================================================================\n\nâš–ï¸  Computing class weights...\nClass weights: {0: 0.6297631862217438, 1: 1.9798646362098138, 2: 1.2163201663201664, 3: 2.0894642857142856, 4: 1.2886563876651982, 5: 1.163121272365805, 6: 0.8491291727140784, 7: 0.47468559837728197, 8: 1.6860230547550432, 9: 0.9148553557466771}\n\n======================================================================\nSTEP 7: TRAIN MODEL\n======================================================================\n\n======================================================================\nğŸš€ STARTING TRAINING\n======================================================================\nEpoch 1/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.5252 - auc: 0.8818 - loss: 1.4004 - precision: 0.6208 - recall: 0.4296\nEpoch 1: val_accuracy improved from -inf to 0.34464, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 129ms/step - accuracy: 0.5255 - auc: 0.8820 - loss: 1.3991 - precision: 0.6211 - recall: 0.4301 - val_accuracy: 0.3446 - val_auc: 0.7524 - val_loss: 3.5148 - val_precision: 0.3626 - val_recall: 0.3337 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8392 - auc: 0.9868 - loss: 0.4039 - precision: 0.8603 - recall: 0.8120\nEpoch 2: val_accuracy improved from 0.34464 to 0.75985, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.8392 - auc: 0.9868 - loss: 0.4038 - precision: 0.8604 - recall: 0.8121 - val_accuracy: 0.7598 - val_auc: 0.9815 - val_loss: 0.5832 - val_precision: 0.7685 - val_recall: 0.7496 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9123 - auc: 0.9953 - loss: 0.2219 - precision: 0.9229 - recall: 0.9047\nEpoch 3: val_accuracy improved from 0.75985 to 0.82151, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 105ms/step - accuracy: 0.9123 - auc: 0.9953 - loss: 0.2219 - precision: 0.9229 - recall: 0.9047 - val_accuracy: 0.8215 - val_auc: 0.9829 - val_loss: 0.6797 - val_precision: 0.8251 - val_recall: 0.8160 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9228 - auc: 0.9945 - loss: 0.2122 - precision: 0.9296 - recall: 0.9173\nEpoch 4: val_accuracy did not improve from 0.82151\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 102ms/step - accuracy: 0.9228 - auc: 0.9945 - loss: 0.2122 - precision: 0.9296 - recall: 0.9173 - val_accuracy: 0.4515 - val_auc: 0.8288 - val_loss: 2.9590 - val_precision: 0.4574 - val_recall: 0.4375 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9353 - auc: 0.9957 - loss: 0.1800 - precision: 0.9406 - recall: 0.9308\nEpoch 5: val_accuracy did not improve from 0.82151\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 102ms/step - accuracy: 0.9354 - auc: 0.9957 - loss: 0.1800 - precision: 0.9406 - recall: 0.9308 - val_accuracy: 0.8116 - val_auc: 0.9758 - val_loss: 0.6050 - val_precision: 0.8218 - val_recall: 0.8040 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9552 - auc: 0.9980 - loss: 0.1170 - precision: 0.9588 - recall: 0.9522\nEpoch 6: val_accuracy did not improve from 0.82151\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 103ms/step - accuracy: 0.9552 - auc: 0.9980 - loss: 0.1170 - precision: 0.9588 - recall: 0.9522 - val_accuracy: 0.6814 - val_auc: 0.9194 - val_loss: 1.4740 - val_precision: 0.6949 - val_recall: 0.6687 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9639 - auc: 0.9987 - loss: 0.0941 - precision: 0.9659 - recall: 0.9614\nEpoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 7: val_accuracy did not improve from 0.82151\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 103ms/step - accuracy: 0.9639 - auc: 0.9987 - loss: 0.0941 - precision: 0.9659 - recall: 0.9614 - val_accuracy: 0.7465 - val_auc: 0.9440 - val_loss: 1.1477 - val_precision: 0.7513 - val_recall: 0.7420 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9738 - auc: 0.9990 - loss: 0.0696 - precision: 0.9755 - recall: 0.9722\nEpoch 8: val_accuracy improved from 0.82151 to 0.89448, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 102ms/step - accuracy: 0.9738 - auc: 0.9990 - loss: 0.0695 - precision: 0.9755 - recall: 0.9722 - val_accuracy: 0.8945 - val_auc: 0.9791 - val_loss: 0.4676 - val_precision: 0.8950 - val_recall: 0.8938 - learning_rate: 5.0000e-04\nEpoch 9/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9808 - auc: 0.9992 - loss: 0.0542 - precision: 0.9817 - recall: 0.9803\nEpoch 9: val_accuracy did not improve from 0.89448\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 103ms/step - accuracy: 0.9808 - auc: 0.9992 - loss: 0.0542 - precision: 0.9817 - recall: 0.9803 - val_accuracy: 0.8887 - val_auc: 0.9824 - val_loss: 0.4127 - val_precision: 0.8898 - val_recall: 0.8876 - learning_rate: 5.0000e-04\nEpoch 10/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9822 - auc: 0.9990 - loss: 0.0526 - precision: 0.9828 - recall: 0.9811\nEpoch 10: val_accuracy did not improve from 0.89448\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9822 - auc: 0.9990 - loss: 0.0526 - precision: 0.9828 - recall: 0.9811 - val_accuracy: 0.8626 - val_auc: 0.9841 - val_loss: 0.4285 - val_precision: 0.8660 - val_recall: 0.8589 - learning_rate: 5.0000e-04\nEpoch 11/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9832 - auc: 0.9989 - loss: 0.0521 - precision: 0.9842 - recall: 0.9828\nEpoch 11: val_accuracy did not improve from 0.89448\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 108ms/step - accuracy: 0.9832 - auc: 0.9989 - loss: 0.0521 - precision: 0.9842 - recall: 0.9828 - val_accuracy: 0.8482 - val_auc: 0.9524 - val_loss: 0.9850 - val_precision: 0.8486 - val_recall: 0.8469 - learning_rate: 5.0000e-04\nEpoch 12/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9854 - auc: 0.9995 - loss: 0.0405 - precision: 0.9858 - recall: 0.9848\nEpoch 12: val_accuracy did not improve from 0.89448\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 105ms/step - accuracy: 0.9854 - auc: 0.9995 - loss: 0.0405 - precision: 0.9858 - recall: 0.9848 - val_accuracy: 0.8787 - val_auc: 0.9876 - val_loss: 0.4018 - val_precision: 0.8790 - val_recall: 0.8787 - learning_rate: 5.0000e-04\nEpoch 13/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9912 - auc: 0.9995 - loss: 0.0292 - precision: 0.9917 - recall: 0.9907\nEpoch 13: val_accuracy did not improve from 0.89448\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 105ms/step - accuracy: 0.9912 - auc: 0.9995 - loss: 0.0292 - precision: 0.9917 - recall: 0.9907 - val_accuracy: 0.8637 - val_auc: 0.9559 - val_loss: 0.8661 - val_precision: 0.8637 - val_recall: 0.8637 - learning_rate: 5.0000e-04\nEpoch 14/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.9812 - auc: 0.9986 - loss: 0.0606 - precision: 0.9814 - recall: 0.9798\nEpoch 14: val_accuracy improved from 0.89448 to 0.96917, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9812 - auc: 0.9986 - loss: 0.0606 - precision: 0.9814 - recall: 0.9798 - val_accuracy: 0.9692 - val_auc: 0.9995 - val_loss: 0.0780 - val_precision: 0.9692 - val_recall: 0.9692 - learning_rate: 5.0000e-04\nEpoch 15/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9890 - auc: 0.9996 - loss: 0.0333 - precision: 0.9898 - recall: 0.9883\nEpoch 15: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9890 - auc: 0.9996 - loss: 0.0333 - precision: 0.9898 - recall: 0.9883 - val_accuracy: 0.7766 - val_auc: 0.9148 - val_loss: 1.6223 - val_precision: 0.7796 - val_recall: 0.7742 - learning_rate: 5.0000e-04\nEpoch 16/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.9873 - auc: 0.9995 - loss: 0.0328 - precision: 0.9878 - recall: 0.9866\nEpoch 16: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 107ms/step - accuracy: 0.9873 - auc: 0.9995 - loss: 0.0328 - precision: 0.9878 - recall: 0.9866 - val_accuracy: 0.8732 - val_auc: 0.9739 - val_loss: 0.5978 - val_precision: 0.8741 - val_recall: 0.8726 - learning_rate: 5.0000e-04\nEpoch 17/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9867 - auc: 0.9991 - loss: 0.0363 - precision: 0.9874 - recall: 0.9867\nEpoch 17: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 107ms/step - accuracy: 0.9867 - auc: 0.9991 - loss: 0.0363 - precision: 0.9874 - recall: 0.9867 - val_accuracy: 0.9517 - val_auc: 0.9966 - val_loss: 0.1481 - val_precision: 0.9517 - val_recall: 0.9510 - learning_rate: 5.0000e-04\nEpoch 18/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9837 - auc: 0.9991 - loss: 0.0476 - precision: 0.9844 - recall: 0.9834\nEpoch 18: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9837 - auc: 0.9991 - loss: 0.0476 - precision: 0.9844 - recall: 0.9834 - val_accuracy: 0.7263 - val_auc: 0.8945 - val_loss: 2.2778 - val_precision: 0.7272 - val_recall: 0.7259 - learning_rate: 5.0000e-04\nEpoch 19/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9889 - auc: 0.9992 - loss: 0.0336 - precision: 0.9892 - recall: 0.9886\nEpoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 19: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 105ms/step - accuracy: 0.9889 - auc: 0.9992 - loss: 0.0336 - precision: 0.9892 - recall: 0.9886 - val_accuracy: 0.9315 - val_auc: 0.9925 - val_loss: 0.2208 - val_precision: 0.9318 - val_recall: 0.9311 - learning_rate: 5.0000e-04\nEpoch 20/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9929 - auc: 0.9997 - loss: 0.0199 - precision: 0.9933 - recall: 0.9929\nEpoch 20: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9929 - auc: 0.9997 - loss: 0.0199 - precision: 0.9933 - recall: 0.9929 - val_accuracy: 0.9445 - val_auc: 0.9904 - val_loss: 0.2468 - val_precision: 0.9448 - val_recall: 0.9445 - learning_rate: 2.5000e-04\nEpoch 21/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 0.0105 - precision: 0.9965 - recall: 0.9965\nEpoch 21: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9965 - auc: 0.9998 - loss: 0.0105 - precision: 0.9965 - recall: 0.9965 - val_accuracy: 0.9267 - val_auc: 0.9900 - val_loss: 0.2797 - val_precision: 0.9267 - val_recall: 0.9267 - learning_rate: 2.5000e-04\nEpoch 22/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9927 - auc: 0.9998 - loss: 0.0192 - precision: 0.9927 - recall: 0.9926\nEpoch 22: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 103ms/step - accuracy: 0.9927 - auc: 0.9998 - loss: 0.0192 - precision: 0.9927 - recall: 0.9926 - val_accuracy: 0.8928 - val_auc: 0.9719 - val_loss: 0.6380 - val_precision: 0.8928 - val_recall: 0.8928 - learning_rate: 2.5000e-04\nEpoch 23/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9963 - auc: 0.9999 - loss: 0.0096 - precision: 0.9963 - recall: 0.9963\nEpoch 23: val_accuracy did not improve from 0.96917\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9963 - auc: 0.9999 - loss: 0.0097 - precision: 0.9963 - recall: 0.9963 - val_accuracy: 0.8585 - val_auc: 0.9469 - val_loss: 1.1798 - val_precision: 0.8585 - val_recall: 0.8585 - learning_rate: 2.5000e-04\nEpoch 24/50\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9944 - auc: 0.9998 - loss: 0.0152 - precision: 0.9945 - recall: 0.9940\nEpoch 24: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 24: val_accuracy improved from 0.96917 to 0.97396, saving model to best_fruit_freshness_model.keras\n\u001b[1m366/366\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - accuracy: 0.9944 - auc: 0.9998 - loss: 0.0152 - precision: 0.9945 - recall: 0.9940 - val_accuracy: 0.9740 - val_auc: 0.9978 - val_loss: 0.0832 - val_precision: 0.9740 - val_recall: 0.9740 - learning_rate: 2.5000e-04\nEpoch 24: early stopping\nRestoring model weights from the end of the best epoch: 14.\n\nâœ… Training completed!\n\n======================================================================\nSTEP 8: SAVE\n======================================================================\n\nğŸ’¾ Training history saved to: training_history.pkl\n\n======================================================================\nâœ… MODEL TRAINING COMPLETE!\n======================================================================\nğŸ“Š Model saved to: best_fruit_freshness_model.keras\nğŸ“Š History saved to: training_history.pkl\n\nâ¡ï¸  Next step: Run 'evaluation_testing.py'\n","output_type":"stream"}],"execution_count":89}]}